{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a3fa4b",
   "metadata": {},
   "source": [
    "# Spacy \n",
    "\n",
    "Spacy uses object oriented programming.\n",
    "\n",
    "Provides most efficient nlp algorithm for a specific task.\n",
    "Hence, if we care about the end result go for spacy\n",
    "\n",
    "Spacy is userfriendly\n",
    "\n",
    "Does not allow to select a particular algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e93322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a027839",
   "metadata": {},
   "source": [
    "## Sentence Tokenization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99642aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ee0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer perceptron (MLP) is a classical feed-forward type of neural networks based on a three-layer structure: input layer, hidden layer and output layer.\n",
      "The multilayer perceptron trained by backpropagation algorithm is the most frequently used technique that was applied in various related problems.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"Multilayer perceptron (MLP) is a classical feed-forward type of neural networks based on a three-layer structure: input layer, hidden layer and output layer. The multilayer perceptron trained by backpropagation algorithm is the most frequently used technique that was applied in various related problems.\")\n",
    "# splitting the text into sentences\n",
    "for sentence in doc.sents:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99eee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer\n",
      "perceptron\n",
      "(\n",
      "MLP\n",
      ")\n",
      "is\n",
      "a\n",
      "classical\n",
      "feed\n",
      "-\n",
      "forward\n",
      "type\n",
      "of\n",
      "neural\n",
      "networks\n",
      "based\n",
      "on\n",
      "a\n",
      "three\n",
      "-\n",
      "layer\n",
      "structure\n",
      ":\n",
      "input\n",
      "layer\n",
      ",\n",
      "hidden\n",
      "layer\n",
      "and\n",
      "output\n",
      "layer\n",
      ".\n",
      "The\n",
      "multilayer\n",
      "perceptron\n",
      "trained\n",
      "by\n",
      "backpropagation\n",
      "algorithm\n",
      "is\n",
      "the\n",
      "most\n",
      "frequently\n",
      "used\n",
      "technique\n",
      "that\n",
      "was\n",
      "applied\n",
      "in\n",
      "various\n",
      "related\n",
      "problems\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddf450",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea03544",
   "metadata": {},
   "source": [
    "NLTK is mainly a string processing library.\n",
    "\n",
    "Provides access to many algorithms. If we want to implement a specific algorithm and do customizations, NLKT is a right choice.\n",
    "Less userfriendly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deede587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a2a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595cbe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multilayer perceptron (MLP.)',\n",
       " 'is a classical feed-forward type of neural networks based on a three-layer structure: input layer, hidden layer and output layer.',\n",
       " 'The multilayer perceptron trained by backpropagation algorithm is the most frequently used technique that was applied in various related problems.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"Multilayer perceptron (MLP.) is a classical feed-forward type of neural networks based on a three-layer structure: input layer, hidden layer and output layer. The multilayer perceptron trained by backpropagation algorithm is the most frequently used technique that was applied in various related problems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ab4ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca411f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multilayer',\n",
       " 'perceptron',\n",
       " '(',\n",
       " 'MLP',\n",
       " '.',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'classical',\n",
       " 'feed-forward',\n",
       " 'type',\n",
       " 'of',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'based',\n",
       " 'on',\n",
       " 'a',\n",
       " 'three-layer',\n",
       " 'structure',\n",
       " ':',\n",
       " 'input',\n",
       " 'layer',\n",
       " ',',\n",
       " 'hidden',\n",
       " 'layer',\n",
       " 'and',\n",
       " 'output',\n",
       " 'layer',\n",
       " '.',\n",
       " 'The',\n",
       " 'multilayer',\n",
       " 'perceptron',\n",
       " 'trained',\n",
       " 'by',\n",
       " 'backpropagation',\n",
       " 'algorithm',\n",
       " 'is',\n",
       " 'the',\n",
       " 'most',\n",
       " 'frequently',\n",
       " 'used',\n",
       " 'technique',\n",
       " 'that',\n",
       " 'was',\n",
       " 'applied',\n",
       " 'in',\n",
       " 'various',\n",
       " 'related',\n",
       " 'problems',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"Multilayer perceptron (MLP.) is a classical feed-forward type of neural networks based on a three-layer structure: input layer, hidden layer and output layer. The multilayer perceptron trained by backpropagation algorithm is the most frequently used technique that was applied in various related problems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c31e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c2eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
